{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-Learning SPAM Classifier\n",
    "- Labelled SPAM/HAM email instances taken from 'https://spamassassin.apache.org/old/publiccorpus/'\n",
    "- Inspired by the contents of Aurelien Geron's Hands-On Machine Learning with Scikit-Learn & TensorFlow book.\n",
    "\n",
    "#### Plan:\n",
    "1. __Parse the emails__ using Python's email package & beautiful soup.\n",
    "2. Use __NLP library spaCy__ to lemmatize the contents of the email & __create a most common lemma vocabulary__.\n",
    "3. __Create vectors__ from the lemma vocabulary Counters.\n",
    "4. Use __Scikit-Learn to train a selection of classification model__.\n",
    "5. __Select the most promising model__'s for __GridSearchCV__ (Logistic Regression & Random Forest Classifier)\n",
    "6. __Evaluate the best model on the test set__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prepare Email Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of HAM: 2500\n",
      "Number of SPAM: 500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "HAM_PATH = '/home/keir/it/1_DS/projects/002_ML_SPAM_FILTER/datasets/20030228_ham0'\n",
    "SPAM_PATH = '/home/keir/it/1_DS/projects/002_ML_SPAM_FILTER/datasets/20030228_spam0'\n",
    "\n",
    "def generate_filenames(ham_path=HAM_PATH, spam_path=SPAM_PATH):\n",
    "    # Return sorted lists containing the names of each file found in the os.listdir(directory)\n",
    "    ham_filenames = [name for name in sorted(os.listdir(ham_path))]\n",
    "    spam_filenames = [name for name in sorted(os.listdir(spam_path))]\n",
    "    return ham_filenames, spam_filenames\n",
    "\n",
    "ham_filenames, spam_filenames = generate_filenames()\n",
    "print('Number of HAM:', len(ham_filenames))\n",
    "print('Number of SPAM:', len(spam_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy as empol\n",
    "\n",
    "# Function to load & parse a specified email name in a given path\n",
    "def load_email(filename, email_path):\n",
    "    with open(os.path.join(email_path, filename), 'rb') as f:\n",
    "        # Return parsed emails\n",
    "        return email.parser.BytesParser(policy=empol.default).parse(f)\n",
    "    \n",
    "    \n",
    "# Create lists of all parsed HAM & SPAM emails\n",
    "ham_emails = [load_email(filename, HAM_PATH) for filename in ham_filenames]\n",
    "spam_emails = [load_email(filename, SPAM_PATH) for filename in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Create a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create array of all the email objects\n",
    "x = np.array(ham_emails + spam_emails)\n",
    "\n",
    "# Create an array containing binary labels in the same order as x (0 for ham_emails & 1 for spam_emails)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "# Create a test set & training set using skikit-learn\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Preprocessing\n",
    "### 3.1 Detect Email HTML & Convert to Text using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    # Create a BS object containing email object contents\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    # Return extracted plain text from the HTML soup - remove newlines & spacing\n",
    "    return soup.get_text().replace('\\n', '').replace(' ', '')\n",
    "\n",
    "def email_to_text(email):\n",
    "    # Set html variable to None for Pythonic if statement at function end\n",
    "    html = None\n",
    "    \n",
    "    # Iterate over all parts & subparts of the email object tree\n",
    "    for part in email.walk():\n",
    "        # Get the email part's or subpart's content type\n",
    "        ctype = part.get_content_type()\n",
    "        # If ctype is not \"text/plain\" or \"text/html\", break this iteration of the for loop\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "\n",
    "        # If the part is not multipart, set content = the part's contents using get_content() to parse\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        # Email part is multipart - set content = the string of a list of the Message objects (payload)\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        \n",
    "        # if there is no HTML in the part, return content (just plain text)\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        # if there is html, set the variable HTML to it\n",
    "        else:\n",
    "            html = content\n",
    "            \n",
    "    # If html has been assigned from the 'for part in email.walk()', convert HTML to plain text & return\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Clean Email Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import urlextract\n",
    "import re\n",
    "# Create an instance of the URL extractor\n",
    "url_extractor = urlextract.URLExtract()\n",
    "\n",
    "\n",
    "class EmailCleaningTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Initialise all variables\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True, \n",
    "                         replace_urls=True, replace_numbers=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        # Create an array with the cleaned emails for all emails passed in as x\n",
    "        emails_transformed = []\n",
    "        for email in x:\n",
    "            # Convert emails to plain text\n",
    "            text = email_to_text(email) or \"\"\n",
    "\n",
    "            # If lower_case=True (default): convert text to lowercase\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "\n",
    "            # Convert all URLs present in the plain text to the word ' URL '\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "\n",
    "            # Use re module (regex) to replace any numbers in the text with the word 'NUMBER'\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "\n",
    "            # Use regex to remove punctuation from text & replace with a ' ' (space)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            \n",
    "            # Append the transformed email \n",
    "            emails_transformed.append(text)\n",
    "        return np.array(emails_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Email Lemmatization To Counter Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "class EmailToLemmaCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, lemmatization=True):\n",
    "        self.lemmatization = lemmatization\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        x_transformed = []\n",
    "        \n",
    "        try:\n",
    "            if self.lemmatization:\n",
    "                # Disable all pipeline components within the with block - just tokenize\n",
    "                with nlp.disable_pipes('tagger', 'parser', 'ner'):\n",
    "                    for email in nlp.pipe(x.tolist()):\n",
    "                        # Make a lemma counter for each email \n",
    "                        lemma_counter = Counter()\n",
    "                        \n",
    "                        \n",
    "                        for token in email:\n",
    "                            if not token.is_stop:\n",
    "                                lemma_counter[token.lemma_] += 1\n",
    "                        # Add each email's lemma counter to the new dataset\n",
    "                        x_transformed.append(lemma_counter)\n",
    "        except:\n",
    "            print('Error')\n",
    "            \n",
    "        return np.array(x_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 General Counter To Vector Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class CounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, vocab_size=15):\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        total_counter = Counter()\n",
    "        for count in x:\n",
    "            for i, count in count.items():\n",
    "                # use min(count, 10) to stop any one email lemma counter outlier overpower \n",
    "                total_counter[i] += min(count, 10)\n",
    "        # Find the most common lemmas - number of them determined by lemma_vocab_size         \n",
    "        most_common = total_counter.most_common()[:self.vocab_size]\n",
    "        # Add entity counts for each of the vocabulary words to the lemma_vocabulary_ class attribute\n",
    "        self.most_common = most_common\n",
    "        self.vocabulary_ = {i: index + 1 for index, (i, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        \n",
    "        for row, count in enumerate(x):\n",
    "            for i, count in count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(i, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(x), self.vocab_size + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Preprocessing Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_clean\", EmailCleaningTransformer()),\n",
    "    (\"email_to_counter\", EmailToLemmaCounterTransformer()),\n",
    "    (\"counter_to_vector\", CounterToVectorTransformer(vocab_size=4500))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed = preprocess_pipeline.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Train a Selection of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove scikit-learn warnings!\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.979, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.979, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.988, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.990, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.985, total=   0.1s\n",
      "Mean Accuracy:  0.9841666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "\n",
    "score = cross_val_score(log_clf, x_train_transformed, y_train, cv=5, verbose=3)\n",
    "print(\"Mean Accuracy: \", score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.956, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.965, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.975, total=   0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.973, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.973, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9683333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "score = cross_val_score(rfc, x_train_transformed, y_train, cv=5, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.952, total=   0.2s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.942, total=   0.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.927, total=   0.2s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.919, total=   0.2s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.929, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9337499999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "score = cross_val_score(gnb, x_train_transformed.toarray(), y_train, cv=5, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.725, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.725, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.700, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.721, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.710, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7162499999999999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "score = cross_val_score(knn, x_train_transformed, y_train, cv=5, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 GridSearchCV Hyperparameter Tuning\n",
    "- GridSearchCV the most promising models - LogisticRegression & RandomForestClassifier\n",
    "\n",
    "\n",
    "### 6.1 Logistic Regression Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=42, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'C': [9, 10, 11], 'penalty': ['l1', 'l2'],\n",
       "                          'solver': ['liblinear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_log = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "     'C' : [9, 10, 11],\n",
    "    'solver' : ['liblinear'],\n",
    "    }]\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "grid_search_log = GridSearchCV(log_clf, param_grid=param_grid_log, cv = 5, verbose=True, n_jobs=-1)\n",
    "grid_search_log.fit(x_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 9, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1972,   23],\n",
       "       [  24,  381]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(grid_search_log.best_estimator_, x_train_transformed, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.943069306930693\n",
      "Recall: 0.9407407407407408\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {precision_score(y_train, y_train_pred)}')\n",
    "print(f'Recall: {recall_score(y_train, y_train_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'bootstrap': [True, False],\n",
       "                          'max_features': [25, 50, 100],\n",
       "                          'n_estimators': [10, 1000, 1500]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_rfc = [\n",
    "    {'n_estimators' : [10, 1000, 1500],\n",
    "     'max_features' : [25, 50, 100],\n",
    "     'bootstrap' : [True, False] \n",
    "    }]\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "grid_search_rf = GridSearchCV(rf_clf, param_grid=param_grid_rfc, cv = 5, n_jobs=-1)\n",
    "grid_search_rf.fit(x_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'max_features': 100, 'n_estimators': 1500}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1981,   14],\n",
       "       [  37,  368]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(grid_search_rf.best_estimator_, x_train_transformed, y_train, cv=5)\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9633507853403142\n",
      "Recall: 0.908641975308642\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {precision_score(y_train, y_train_pred)}')\n",
    "print(f'Recall: {recall_score(y_train, y_train_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Final Model & Test Set Evaluation\n",
    "- Evaluate the final model (Logistic Regression Classifier) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_transformed = preprocess_pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = final_model.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 98%\n",
      "\n",
      "Precision: 92%\n",
      "Recall: 97%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score: {:.0f}%'.format(100*accuracy_score(y_test, final_predictions)))\n",
    "print()\n",
    "print(\"Precision: {:.0f}%\".format(100 * precision_score(y_test, final_predictions)))\n",
    "print(\"Recall: {:.0f}%\".format(100 * recall_score(y_test, final_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- __spaCy's lemmatization is not as effective as NLTK stemming__ for this particular dataset (in both recall & precision), however spaCy was more fun!\n",
    "- Performing email length analysis, structure analysis, and spaCy entity analysis diluted the effectiveness of stemming & lemmatization. \n",
    "- Could __manipulate the decision function's threshold to balance precision & recall__ if desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
